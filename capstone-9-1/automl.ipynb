{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "import azureml.core\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "from azureml.core.model import Model, InferenceConfig\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "from azureml.core import Environment\n",
        "from azureml.core.webservice import AciWebservice\n",
        "import requests\n",
        "import json\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.51.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1693580277830
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azureml-widgets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azureml-widgets\r\nVersion: 1.51.0\r\nSummary: Provides fully supported, with interactivity, async auto-updates, and non-blocking cell execution.\r\nHome-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\nAuthor: Microsoft Corp\r\nAuthor-email: None\r\nLicense: https://aka.ms/azureml-sdk-license\r\nLocation: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\r\nRequires: jinja2, azureml-core, ipywidgets, azure-storage-blob, azureml-telemetry\r\nRequired-by: \r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1693580289228
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "myenv = Environment(name = \"myenv\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1693580297544
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "myenv.register(workspace=ws)\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'maternal-health-automl-exp'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1693580311487
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.get_by_name(ws, name='maternal-health-risk')\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1693580319844
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = { \"experiment_timeout_minutes\": 30,\n",
        "                    \"max_concurrent_iterations\": 5,\n",
        "                    \"primary_metric\" : 'accuracy'}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "                             task = \"classification\",\n",
        "                             training_data=df,\n",
        "                             label_column_name=\"Outcome\",  \n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1693580327282
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "remote_run = AutoMLRun(experiment = experiment, run_id = 'AutoML_9d4ad407-d089-41e7-85f1-fc88df4ab866')"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1693580342512
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(remote_run.get_file_names())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['definition.json', 'definition_original.json', 'outputs/_automl_internal/_CACHE_STORE_KEY_ONNX_CONVERTER_INIT_METADATA_.pkl', 'outputs/_automl_internal/indices/861553f469944289acaa5cf0d54c7d94.json', 'outputs/verifier_results.json']\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1693580346584
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1.51.0\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1693580350241
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(remote_run).show()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'remote_run' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunDetails\n\u001b[0;32m----> 2\u001b[0m RunDetails(\u001b[43mremote_run\u001b[49m)\u001b[38;5;241m.\u001b[39mshow()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'remote_run' is not defined"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1693585710633
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_details = remote_run.get_details()\n",
        "print(run_details)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'runId': 'AutoML_9d4ad407-d089-41e7-85f1-fc88df4ab866', 'target': 'notebook240923', 'status': 'Completed', 'startTimeUtc': '2023-09-01T14:55:27.517319Z', 'endTimeUtc': '2023-09-01T15:21:51.717023Z', 'services': {}, 'warnings': [{'source': 'JasmineService', 'message': 'No scores improved over last 20 iterations, so experiment stopped early. This early stopping behavior can be disabled by setting enable_early_stopping = False in AutoMLConfig for notebook/python SDK runs.'}], 'properties': {'num_iterations': '1000', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'primary_metric': 'AUC_weighted', 'train_split': '0', 'acquisition_parameter': '0', 'num_cross_validation': None, 'target': 'notebook240923', 'AMLSettingsJsonString': '{\"enable_early_stopping\":true,\"enable_ensembling\":true,\"enable_stack_ensembling\":true,\"ensemble_iterations\":15,\"enable_onnx_compatible_models\":false,\"save_mlflow\":true,\"max_cores_per_iteration\":-1,\"send_telemetry\":true,\"blacklist_algos\":[\"TensorFlowLinearClassifier\",\"TensorFlowDNN\"],\"whitelist_models\":null,\"compute_target\":\"notebook240923\",\"enable_dnn\":false,\"enable_code_generation\":true,\"experiment_exit_score\":null,\"experiment_timeout_minutes\":30,\"featurization\":\"auto\",\"hyperdrive_config\":null,\"grain_column_names\":null,\"is_timeseries\":false,\"iteration_timeout_minutes\":30,\"max_concurrent_iterations\":3,\"metric_operation\":\"maximize\",\"model_explainability\":true,\"n_cross_validations\":null,\"name\":\"maternal-health-automl-exp\",\"path\":\"./sample_projects/maternal-health-automl-exp\",\"primary_metric\":\"AUC_weighted\",\"region\":\"westus2\",\"resource_group\":\"aml-quickstarts-240923\",\"subscription_id\":\"d4ad7261-832d-46b2-b093-22156001df5b\",\"task_type\":\"classification\",\"validation_size\":null,\"test_size\":null,\"vm_type\":\"STANDARD_DS3_V2\",\"workspace_name\":\"quick-starts-ws-240923\",\"label_column_name\":\"HighRisk\",\"positive_label\":null,\"enable_batch_run\":true,\"dataset_id\":\"edae7be1-92d0-42fd-8328-9d2ea427a014\"}', 'DataPrepJsonString': '{\\\\\"datasets\\\\\":0,\\\\\"training_data\\\\\":{\\\\\"datasetId\\\\\":\\\\\"edae7be1-92d0-42fd-8328-9d2ea427a014\\\\\"}}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'azureml.runsource': 'automl', '_aml_system_scenario_identification': 'Remote.Parent', 'ClientType': 'Browser', 'PlatformVersion': 'DPV1', 'environment_cpu_name': 'AzureML-AutoML', 'environment_cpu_label': 'prod', 'environment_gpu_name': 'AzureML-AutoML-GPU', 'environment_gpu_label': 'prod', 'root_attribution': 'automl', 'attribution': 'AutoML', 'Orchestrator': 'AutoML', 'CancelUri': 'https://westus2.api.azureml.ms/jasmine/v1.0/subscriptions/d4ad7261-832d-46b2-b093-22156001df5b/resourceGroups/aml-quickstarts-240923/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-240923/experiment/maternal-health-automl-exp/cancel/AutoML_9d4ad407-d089-41e7-85f1-fc88df4ab866', 'ClientSdkVersion': None, 'snapshotId': '00000000-0000-0000-0000-000000000000', 'SetupRunId': 'AutoML_9d4ad407-d089-41e7-85f1-fc88df4ab866_setup', 'SetupRunContainerId': 'dcid.AutoML_9d4ad407-d089-41e7-85f1-fc88df4ab866_setup', 'FeaturizationRunJsonPath': 'featurizer_container.json', 'FeaturizationRunId': 'AutoML_9d4ad407-d089-41e7-85f1-fc88df4ab866_featurize', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"has_extra_col\": true, \"dataset_classes\": 2, \"dataset_features\": 108, \"dataset_samples\": 1014, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': 'AutoML_9d4ad407-d089-41e7-85f1-fc88df4ab866_ModelExplain'}, 'inputDatasets': [{'dataset': {'id': 'edae7be1-92d0-42fd-8328-9d2ea427a014'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'logFiles': {}, 'submittedBy': 'ODL_User 240923'}\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1693582076518
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "auto_job, best_auto_model = remote_run.get_output()\n",
        "print(auto_job)\n",
        "print(best_auto_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:The version of the SDK does not match the version the model was trained on.\nWARNING:root:The consistency in the result may not be guaranteed.\nWARNING:root:Package:azureml-automl-core, training version:1.52.0.post1, current version:1.51.0.post1\nPackage:azureml-automl-runtime, training version:1.52.0.post1, current version:1.51.0.post1\nPackage:azureml-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-dataprep, training version:4.11.4, current version:4.10.8\nPackage:azureml-dataprep-rslex, training version:2.18.4, current version:2.17.12\nPackage:azureml-dataset-runtime, training version:1.52.0, current version:1.51.0\nPackage:azureml-defaults, training version:1.52.0, current version:1.51.0\nPackage:azureml-interpret, training version:1.52.0, current version:1.51.0\nPackage:azureml-mlflow, training version:1.52.0, current version:1.51.0\nPackage:azureml-pipeline-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-responsibleai, training version:1.52.0, current version:1.51.0\nPackage:azureml-telemetry, training version:1.52.0, current version:1.51.0\nPackage:azureml-train-automl-client, training version:1.52.0, current version:1.51.0.post1\nPackage:azureml-train-automl-runtime, training version:1.52.0, current version:1.51.0.post2\nPackage:azureml-train-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-train-restclients-hyperdrive, training version:1.52.0, current version:1.51.0\nPackage:azureml-training-tabular, training version:1.52.0, current version:1.51.0.post1\nWARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run(Experiment: maternal-health-automl-exp,\nId: AutoML_9d4ad407-d089-41e7-85f1-fc88df4ab866_44,\nType: azureml.scriptrun,\nStatus: Completed)\nPipeline(memory=None,\n         steps=[('datatransformer',\n                 DataTransformer(enable_dnn=False, enable_feature_sweeping=False, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mnt/batch/tasks/shared/LS_root/moun...\n                 PreFittedSoftVotingClassifier(classification_labels=array([0, 1]), estimators=[('14', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('1', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('xgboostclassifier', XGBoostClassifier(n_jobs=0, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, tree_method='auto'))], verbose=False)), ('0', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('lightgbmclassifier', LightGBMClassifier(min_data_in_leaf=20, n_jobs=-1, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None))], verbose=False)), ('39', Pipeline(memory=None, steps=[('sparsenormalizer', Normalizer(copy=True, norm='l1')), ('xgboostclassifier', XGBoostClassifier(booster='gbtree', colsample_bytree=0.9, eta=0.2, gamma=0, max_depth=6, max_leaves=3, n_estimators=600, n_jobs=0, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=2.3958333333333335, reg_lambda=1.9791666666666667, subsample=0.9, tree_method='auto'))], verbose=False)), ('42', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('xgboostclassifier', XGBoostClassifier(booster='gbtree', colsample_bytree=1, eta=0.2, gamma=0.01, max_depth=5, max_leaves=0, n_estimators=100, n_jobs=0, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=0, reg_lambda=0.9375, subsample=0.5, tree_method='auto'))], verbose=False)), ('33', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('lightgbmclassifier', LightGBMClassifier(boosting_type='gbdt', colsample_bytree=0.1, learning_rate=0.04737368421052632, max_bin=100, max_depth=5, min_child_weight=9, min_data_in_leaf=0.003457931034482759, min_split_gain=0.7368421052631579, n_estimators=200, n_jobs=-1, num_leaves=194, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None, reg_alpha=0.7368421052631579, reg_lambda=1, subsample=0.5447368421052632))], verbose=False)), ('11', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesclassifier', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced', criterion='entropy', max_depth=None, max_features='log2', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.01, min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=-1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False))], flatten_transform=None, weights=[0.25, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]))],\n         verbose=False)\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1693582096513
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the best model\n",
        "joblib.dump(value=best_auto_model, filename='auto_model.joblib')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "['auto_model.joblib']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1693582108919
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = auto_job.register_model(model_name='best-automl-model',\n",
        "                                      model_path='outputs/model.pkl',\n",
        "                                      description='Best model from AutoML for maternal health risk')"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1693582218583
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auto_job.download_files(output_directory='automl_output')\n",
        "\n",
        "env = Environment.from_conda_specification('automl-env', 'conda_dependencies.yml')\n",
        "\n",
        "inference = InferenceConfig(environment=env, entry_script='./Score2.py')\n",
        "\n",
        "deployment = AciWebservice.deploy_configuration(cpu_cores=1,\n",
        "                                                       memory_gb=1,\n",
        "                                                       enable_app_insights=True)\n",
        "\n",
        "deployment_name = 'auto-maternal-risk'\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name=deployment_name,\n",
        "                       models=[model],\n",
        "                       inference_config=inference,\n",
        "                       deployment_config=deployment,\n",
        "                       overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-09-01 15:32:47+00:00 Creating Container Registry if not exists.\n2023-09-01 15:32:47+00:00 Registering the environment.\n2023-09-01 15:32:48+00:00 Building image..\n2023-09-01 15:43:14+00:00 Generating deployment configuration.\n2023-09-01 15:43:15+00:00 Submitting deployment to compute..\n2023-09-01 15:43:20+00:00 Checking the status of deployment auto-maternal-risk..\n2023-09-01 15:45:16+00:00 Checking the status of inference endpoint auto-maternal-risk.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1693583142857
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "data =  {\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"Age\": 0,\n",
        "      \"SystolicBP\": 0,\n",
        "      \"DiastolicBP\": 0,\n",
        "      \"BS\": 15.0,\n",
        "      \"BodyTemp\": 0,\n",
        "      \"HeartRate\": 0\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "url = 'http://17d79f0f-0926-4a48-b0a7-5e054aaa6758.westus2.azurecontainer.io/score'\n",
        "\n",
        "\n",
        "headers = {'Content-Type':'application/json'}\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "b'\"{\\\\\"result\\\\\": [1]}\"'\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693586271146
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logs = service.get_logs()\n",
        "for line in logs.split('\\n'):\n",
        "    print(line)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/bin/bash: /azureml-envs/azureml_d23c40ccd7225ebe3e23cbbc514bfe04/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_d23c40ccd7225ebe3e23cbbc514bfe04/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_d23c40ccd7225ebe3e23cbbc514bfe04/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2023-09-01T15:45:07,541968100+00:00 - rsyslog/run \n2023-09-01T15:45:07,551178400+00:00 - gunicorn/run \n2023-09-01T15:45:07,552636700+00:00 | gunicorn/run | \nbash: /azureml-envs/azureml_d23c40ccd7225ebe3e23cbbc514bfe04/lib/libtinfo.so.6: no version information available (required by bash)\n2023-09-01T15:45:07,560477600+00:00 | gunicorn/run | ###############################################\n2023-09-01T15:45:07,562534500+00:00 | gunicorn/run | AzureML Container Runtime Information\n2023-09-01T15:45:07,568880100+00:00 | gunicorn/run | ###############################################\n2023-09-01T15:45:07,570640900+00:00 | gunicorn/run | \n2023-09-01T15:45:07,572596400+00:00 | gunicorn/run | \n2023-09-01T15:45:07,592756100+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230509.v1\n2023-09-01T15:45:07,598442100+00:00 | gunicorn/run | \n2023-09-01T15:45:07,600804700+00:00 - nginx/run \n2023-09-01T15:45:07,601618900+00:00 | gunicorn/run | \n2023-09-01T15:45:07,609572800+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_d23c40ccd7225ebe3e23cbbc514bfe04/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2023-09-01T15:45:07,611364100+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2023-09-01T15:45:07,617421400+00:00 | gunicorn/run | \n2023-09-01T15:45:09,378593200+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\n                      *  /azureml-envs/azureml_d23c40ccd7225ebe3e23cbbc514bfe04\nbase                     /opt/miniconda\n\n2023-09-01T15:45:11,774713048+00:00 | gunicorn/run | \n2023-09-01T15:45:11,779576439+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nadal==1.2.7\nappdirs==1.4.4\napplicationinsights==0.11.10\narch==5.3.1\nargcomplete==2.1.2\nattrs==23.1.0\nazure-common==1.1.28\nazure-core==1.29.3\nazure-graphrbac==0.61.1\nazure-identity==1.14.0\nazure-mgmt-authorization==3.0.0\nazure-mgmt-containerregistry==10.1.0\nazure-mgmt-core==1.4.0\nazure-mgmt-keyvault==10.2.3\nazure-mgmt-network==21.0.1\nazure-mgmt-resource==22.0.0\nazure-mgmt-storage==21.0.0\nazureml-automl-core==1.53.0\nazureml-automl-runtime==1.53.0.post1\nazureml-core==1.53.0\nazureml-dataprep==4.12.1\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.19.1\nazureml-dataset-runtime==1.53.0\nazureml-defaults==1.53.0\nazureml-inference-server-http==0.8.4.1\nazureml-interpret==1.53.0\nazureml-telemetry==1.53.0\nazureml-training-tabular==1.53.0.post1\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\nBoruta==0.3\nboto==2.49.0\nboto3==1.20.19\nbotocore==1.23.19\nBottleneck @ file:///opt/conda/conda-bld/bottleneck_1657175564434/work\nbrotlipy==0.7.0\ncachetools==5.3.1\ncertifi @ file:///croot/certifi_1690232220950/work/certifi\ncffi @ file:///croot/cffi_1670423208954/work\ncharset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work\nclick==8.1.7\ncloudpickle==2.2.1\ncoloredlogs==15.0.1\ncontextlib2==21.6.0\ncontourpy==1.1.0\ncryptography @ file:///croot/cryptography_1689373676338/work\ncycler==0.11.0\nCython==0.29.17\ndataclasses==0.6\ndill==0.3.7\ndistro==1.8.0\ndocker==6.1.3\ndotnetcore2==3.1.23\nfire==0.5.0\nFlask==2.2.5\nFlask-Cors==3.0.10\nflatbuffers==23.5.26\nfonttools==4.42.1\nfusepy==3.0.1\ngensim==3.8.3\ngoogle-api-core==2.11.1\ngoogle-auth==2.22.0\ngoogleapis-common-protos==1.60.0\ngunicorn==20.1.0\nhumanfriendly==10.0\nidna @ file:///croot/idna_1666125576474/work\nimportlib-metadata==6.8.0\nimportlib-resources==6.0.1\ninference-schema==1.5.1\ninterpret-community==0.29.0\ninterpret-core==0.3.2\nisodate==0.6.1\nitsdangerous==2.1.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==0.10.0\njoblib @ file:///croot/joblib_1685113087166/work\njsonpickle==3.0.2\njsonschema==4.19.0\njsonschema-specifications==2023.7.1\nkeras2onnx==1.6.0\nkiwisolver==1.4.5\nknack==0.10.1\nlightgbm==3.2.1\nlittleutils==0.2.2\nllvmlite==0.38.1\nMarkupSafe==2.1.3\nmatplotlib==3.7.2\nmkl-fft==1.3.6\nmkl-random @ file:///work/mkl/mkl_random_1682950433854/work\nmkl-service==2.4.0\nml-wrappers==0.4.13\nmpmath==1.3.0\nmsal==1.23.0\nmsal-extensions==1.0.0\nmsrest==0.7.1\nmsrestazure==0.6.4\nndg-httpsclient==0.5.1\nnumba==0.55.2\nnumexpr @ file:///croot/numexpr_1683221822650/work\nnumpy==1.22.3\noauthlib==3.2.2\nonnx==1.14.1\nonnxconverter-common==1.13.0\nonnxmltools==1.11.2\nonnxruntime==1.14.1\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\noutdated==0.2.2\npackaging==23.0\npandas==1.1.5\npandas-flavor==0.6.0\nparamiko==3.3.1\npathspec==0.11.2\npatsy==0.5.3\nPillow==10.0.0\npingouin==0.3.12\npkginfo==1.9.6\npkgutil_resolve_name==1.3.10\npmdarima==1.8.0\npooch @ file:///tmp/build/80754af9/pooch_1623324770023/work\nportalocker==2.7.0\nproperty-cached==1.6.4\nprotobuf==3.20.3\npsutil==5.9.5\npyarrow==11.0.0\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\npydantic==1.10.12\nPygments==2.16.1\nPyJWT==2.8.0\nPyNaCl==1.5.0\npyOpenSSL @ file:///croot/pyopenssl_1690223430423/work\npyparsing==3.0.9\nPySocks @ file:///tmp/build/80754af9/pysocks_1605305779399/work\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\npytz @ file:///croot/pytz_1671697431263/work\nPyYAML==6.0.1\nraiutils==0.4.1\nreferencing==0.30.2\nrequests @ file:///croot/requests_1690400202158/work\nrequests-oauthlib==1.3.1\nrpds-py==0.10.0\nrsa==4.9\ns3transfer==0.5.2\nscikit-learn==1.1.0\nscipy==1.5.3\nseaborn==0.12.2\nSecretStorage==3.3.3\nshap==0.41.0\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\nskl2onnx==1.14.1\nsklearn-pandas==1.7.0\nslicer==0.0.7\nsmart-open==1.9.0\nstatsmodels==0.11.1\nsympy==1.12\ntabulate==0.9.0\ntermcolor==2.3.0\nthreadpoolctl @ file:///Users/ktietz/demo/mc3/conda-bld/threadpoolctl_1629802263681/work\ntqdm==4.66.1\ntyping_extensions==4.7.1\ntzdata @ file:///croot/python-tzdata_1690578112552/work\nurllib3 @ file:///croot/urllib3_1686163155763/work\nwebsocket-client==1.6.2\nWerkzeug==2.3.7\nwrapt==1.12.1\nxarray==2022.3.0\nxgboost==1.4.2\nzipp==3.16.2\n\n2023-09-01T15:45:13,628858825+00:00 | gunicorn/run | \n2023-09-01T15:45:13,631132625+00:00 | gunicorn/run | ###############################################\n2023-09-01T15:45:13,639232425+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2023-09-01T15:45:13,641520825+00:00 | gunicorn/run | ###############################################\n2023-09-01T15:45:13,647086025+00:00 | gunicorn/run | \n2023-09-01T15:45:16,722374925+00:00 | gunicorn/run | \n2023-09-01T15:45:16,725957425+00:00 | gunicorn/run | ###############################################\n2023-09-01T15:45:16,732369825+00:00 | gunicorn/run | AzureML Inference Server\n2023-09-01T15:45:16,735465025+00:00 | gunicorn/run | ###############################################\n2023-09-01T15:45:16,737456625+00:00 | gunicorn/run | \n2023-09-01T15:45:19,972889968+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n2023-09-01 15:45:20,435 I [75] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_d23c40ccd7225ebe3e23cbbc514bfe04/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n2023-09-01 15:45:20,728 I [75] gunicorn.error - Starting gunicorn 20.1.0\n2023-09-01 15:45:20,729 I [75] gunicorn.error - Listening at: http://0.0.0.0:31311 (75)\n2023-09-01 15:45:20,729 I [75] gunicorn.error - Using worker: sync\n2023-09-01 15:45:20,748 I [146] gunicorn.error - Booting worker with pid: 146\nValid Application Insights instrumentation key provided.\n\nAzure ML Inferencing HTTP server v0.8.4.1\n\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/Score2.py\nModel Directory: /var/azureml-app/azureml-models/best-automl-model/2\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: true\nApplication Insights Key: AppInsights key provided\nInferencing HTTP server version: azmlinfsrv/0.8.4.1\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n2023-09-01 15:45:21,832 I [146] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\nInitializing logger\n2023-09-01 15:45:21,837 I [146] azmlinfsrv - Starting up app insights client\nWARNING:opencensus.ext.azure.common:DeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\nWARNING:opencensus.ext.azure.common:DeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\nWARNING:opencensus.ext.azure.common:DeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\n2023-09-01 15:45:28,311 I [146] azmlinfsrv.user_script - Found user script at /var/azureml-app/Score2.py\n2023-09-01 15:45:28,311 I [146] azmlinfsrv.user_script - run() is decorated with @input_schema. Server will invoke it with the following arguments: data.\n2023-09-01 15:45:28,311 I [146] azmlinfsrv.user_script - Invoking user's init function\n2023-09-01 15:45:39,844 I [146] azmlinfsrv.user_script - Users's init has completed successfully\n2023-09-01 15:45:39,924 I [146] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n2023-09-01 15:45:39,924 I [146] azmlinfsrv - Scoring timeout is set to 60000\n2023-09-01 15:45:39,924 I [146] azmlinfsrv - Worker with pid 146 ready for serving traffic\n2023-09-01 15:45:39,934 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:45:39 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"curl/7.58.0\"\n2023-09-01 15:45:39,936 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:45:39,943 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:45:39 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-01 15:45:39,944 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:45:39,945 I [146] azmlinfsrv - GET /swagger.json 200 0.876ms 2901\n2023-09-01 15:45:39,948 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:45:39 +0000] \"GET /swagger.json HTTP/1.0\" 200 2901 \"-\" \"Go-http-client/1.1\"\n2023-09-01 15:45:41,920 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:45:41,922 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:45:41 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-01 15:45:41,928 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:45:41,929 I [146] azmlinfsrv - GET /swagger.json 200 0.885ms 2901\n2023-09-01 15:45:41,930 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:45:41 +0000] \"GET /swagger.json HTTP/1.0\" 200 2901 \"-\" \"Go-http-client/1.1\"\n2023-09-01 15:46:19,436 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:46:19,437 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:46:19 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-01 15:46:19,448 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:46:19,448 I [146] azmlinfsrv - GET /swagger.json 200 0.565ms 2901\n2023-09-01 15:46:19,450 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:46:19 +0000] \"GET /swagger.json HTTP/1.0\" 200 2901 \"-\" \"Go-http-client/1.1\"\n2023-09-01 15:46:29,252 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:46:29,252 I [146] azmlinfsrv - GET /swagger.json 200 0.743ms 2901\n2023-09-01 15:46:29,254 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:46:29 +0000] \"GET /swagger.json HTTP/1.0\" 200 2901 \"-\" \"Go-http-client/1.1\"\n2023-09-01 15:46:49,191 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:46:49,904 I [146] azmlinfsrv - POST /score 200 714.067ms 19\n2023-09-01 15:46:49,907 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:46:49 +0000] \"POST /score HTTP/1.0\" 200 19 \"-\" \"Python-urllib/3.8\"\n2023-09-01 15:47:02,635 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-01 15:47:03,318 I [146] azmlinfsrv - POST /score 200 683.461ms 19\n2023-09-01 15:47:03,320 I [146] gunicorn.access - 127.0.0.1 - - [01/Sep/2023:15:47:03 +0000] \"POST /score HTTP/1.0\" 200 19 \"-\" \"python-requests/2.31.0\"\n\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1693583249099
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the Webservice and Compute Cluster\n",
        "service.delete()\n",
        "compute_target.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}